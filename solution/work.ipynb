{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730676c8",
   "metadata": {},
   "source": [
    "# Coffee Shop ETL\n",
    "#### Omrahn Faqiri - 991 732 187\n",
    "\n",
    "---\n",
    "\n",
    "### Instructions:\n",
    "Just change the `CURRENT_DAY` variable to either `\"day1\"`, `\"day2\"`, or `\"day3\"` depending on the day and run all cells in order. Refactoring everything from a pynb to a single python file was overcomplicating everything, so I left is as a notebook.\n",
    "\n",
    "The current `/database/schema/dim_suppliers.csv` file is populated with the result of the third day. Just clear everything but the header row and run the days 1-3 and it should give the same output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32a0802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DAY = 'day3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89bade8",
   "metadata": {},
   "source": [
    "### Notes\n",
    "---\n",
    "#### SCD Type 2 Triggers (new row):\n",
    "- `supplier_name`\n",
    "- `supplier_category`\n",
    "- `city`\n",
    "- `delivery_frequency`\n",
    "- `email`\n",
    "\n",
    "> Create new row, assign new `supplier_key`, mark `is_active` as `True`, mark old row's `is_active` as `False`\n",
    "\n",
    "#### SCD Type 1 Triggers (overwrite):\n",
    "- `notes`\n",
    "- `is_active`\n",
    "\n",
    "> Just overwrite these bro\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdef1002",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccc74c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data/day1/supplier_details.csv and suppliers.csv into pandas\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Paths\n",
    "DIM_SUPPLIERS_PATH = \"../database/schema/dim_suppliers.csv\"\n",
    "DETAILS_PATH = f\"../data/{CURRENT_DAY}/supplier_details.csv\"\n",
    "SUPPLIERS_PATH = f\"../data/{CURRENT_DAY}/suppliers.csv\"\n",
    "\n",
    "# Triggers\n",
    "TYPE2 = [\"supplier_name\",\"supplier_category\",\"city\",\"delivery_frequency\",\"email\"]\n",
    "TYPE1 = [\"notes\",\"is_active\"]\n",
    "\n",
    "# Daily Dataframes\n",
    "details = pd.read_csv(DETAILS_PATH)\n",
    "suppliers = pd.read_csv(SUPPLIERS_PATH)\n",
    "\n",
    "# Ensure that there is a dim_suppliers to work with\n",
    "if os.path.exists(DIM_SUPPLIERS_PATH) and os.path.getsize(DIM_SUPPLIERS_PATH) > 0:\n",
    "    dim_suppliers = pd.read_csv(DIM_SUPPLIERS_PATH)\n",
    "    # Convert is_active to boolean if it exists\n",
    "    if 'is_active' in dim_suppliers.columns:\n",
    "        dim_suppliers['is_active'] = dim_suppliers['is_active'].astype(bool)\n",
    "else:\n",
    "    dim_suppliers = pd.DataFrame() # start empty\n",
    "\n",
    "# just to make the day mapping a bit more dynamic\n",
    "def get_days_mapping(day: str):\n",
    "    days_mapping = {\n",
    "        'day1' : '2025-01-01',\n",
    "        'day2' : '2025-01-02',\n",
    "        'day3' : '2025-01-03'\n",
    "    }\n",
    "    return days_mapping[day]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fc8478",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9416cac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suppliers:    SupplierID          SupplierName SupplierCategory         City  IsActive\n",
      "0         101  BeanRoasters Company     Coffee Beans  Mississauga      True\n",
      "1         102    SweetTreats Bakery           Bakery  Mississauga      True\n",
      "2         104     CupTech Equipment        Equipment      Toronto      True\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "details:    SupplierID                     Email DeliveryFrequency  \\\n",
      "0         101  contact@beanroasters.com            Weekly   \n",
      "1         102       info@sweettreats.ca             Daily   \n",
      "2         104       support@cuptech.com           Monthly   \n",
      "\n",
      "                            Notes  \n",
      "0          Expanded delivery area  \n",
      "1                  Same as before  \n",
      "2  Now offers maintenance service  \n",
      "||||||||||||||||||||||||||||||||||| [Data Types for Reference] |||||||||||||||||||||||||||||||||||\n",
      "SupplierID           int64\n",
      "SupplierName        object\n",
      "SupplierCategory    object\n",
      "City                object\n",
      "IsActive              bool\n",
      "dtype: object \n",
      "\n",
      "\n",
      " SupplierID            int64\n",
      "Email                object\n",
      "DeliveryFrequency    object\n",
      "Notes                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "def clean(df_supp, df_det):\n",
    "    # strip whitespace from strings\n",
    "    df_supp = df_supp.map(lambda x: x.strip() if isinstance (x, str) else x)\n",
    "    df_det = df_det.map(lambda x: x.strip() if isinstance (x, str) else x)\n",
    "    # lowercase all emails\n",
    "    df_det[\"Email\"] = df_det[\"Email\"].str.lower()\n",
    "\n",
    "    # suppliers.dtypes already shows 'is_active' as bool\n",
    "\n",
    "    return df_supp, df_det\n",
    "\n",
    "suppliers, details = clean(suppliers, details)\n",
    "print(\"suppliers:\",suppliers.head(3))\n",
    "print(\"\\n\" + \"-\"*90)\n",
    "print(\"details:\",details.head(3))\n",
    "print(f\"{\"|\"*35} [Data Types for Reference] {\"|\"*35}\")\n",
    "print(f\"{suppliers.dtypes} \\n\\n\\n {details.dtypes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced9fd10",
   "metadata": {},
   "source": [
    "# Staging & Metadata\n",
    "---\n",
    "### Notes:\n",
    "- first day has only 8 entreis anyway\n",
    "- `source_date` for day 1 will be null since we don't *actually know* the source date.\n",
    "  - day 2 will have a source date of '2025-01-01'\n",
    "  - day 3 will have a source date of '2025-01-02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db3e02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stage(df_supp, df_det, day='day1'):\n",
    "    # merge the two dataframes based on the supplier_id\n",
    "    df_staging = df_supp.merge(df_det, on=\"SupplierID\", how=\"inner\")\n",
    "\n",
    "    # rename columns for consistency\n",
    "    df_staging = df_staging.rename(columns={\n",
    "        'SupplierID': 'supplier_id',\n",
    "        'SupplierName': 'supplier_name',\n",
    "        'SupplierCategory': 'supplier_category',\n",
    "        'City': 'city',\n",
    "        'IsActive': \"is_active\",\n",
    "        'Email': 'email',\n",
    "        'DeliveryFrequency': 'delivery_frequency',\n",
    "        'Notes': 'notes'\n",
    "    })\n",
    "\n",
    "    # Drop the duplicate column (i kept having errors here)\n",
    "    if 'supplier_id.1' in df_staging.columns:\n",
    "        df_staging = df_staging.drop(columns=['supplier_id.1'])\n",
    "\n",
    "    # -- add metadata --\n",
    "    # add the source date\n",
    "    df_staging[\"source_date\"] = get_days_mapping(day)\n",
    "    \n",
    "    # update \"last_updated_at\" using isoformat\n",
    "    df_staging[\"last_updated_at\"] = datetime.now().isoformat(timespec='seconds')\n",
    "\n",
    "    return df_staging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d5f408",
   "metadata": {},
   "source": [
    "# Load Current Dimension & Delta Detection/SCD Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6c44eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding deltas for day: day3\n",
      "the new suppliers added: 1\n",
      "Suppliers deactivated (missing from staging): 1\n",
      "Loaded: day3\n",
      "Type 2 count: 3\n",
      "Type 1 counrt: 3\n"
     ]
    }
   ],
   "source": [
    "def load():\n",
    "    # Get the staging & active df\n",
    "    df_staging = stage(suppliers, details, CURRENT_DAY)\n",
    "    df_active = dim_suppliers\n",
    "\n",
    "    # -------- Day 1: Initial Load ------------\n",
    "    # If we're in day 1, load the entire thing since it has no deltas\n",
    "    if df_active.empty:\n",
    "        # add supplier_key starting from 1\n",
    "        df_staging.insert(0, 'supplier_key', range(1, len(df_staging) + 1))\n",
    "        df_staging.to_csv(DIM_SUPPLIERS_PATH, index=False)\n",
    "        print(f\"Day 1: {len(df_staging)} rows loaded\")\n",
    "        return\n",
    "\n",
    "    # -------- Day 2+: Loads  --------\n",
    "    print(f\"Finding deltas for day: {CURRENT_DAY}\")\n",
    "\n",
    "    # Get the rows that are active\n",
    "    df_active_current = df_active[df_active['is_active'] == True].copy()\n",
    "    \n",
    "    # -------- Compare 'df_active_current' with 'df_staging' --------\n",
    "    dim_suppliers_result = df_active.copy() # The df we will be updating & loading into the csv\n",
    "\n",
    "    # Reset indices (for some reason they're different)\n",
    "    df_active_current = df_active_current.reset_index(drop=True)\n",
    "    df_staging = df_staging.reset_index(drop=True)\n",
    "\n",
    "    # Get New Suppliers and append to the result'\n",
    "    active_ids = set(df_active_current['supplier_id'])\n",
    "    staging_ids = set(df_staging['supplier_id'])\n",
    "    new_ids = staging_ids - active_ids\n",
    "    new_suppliers = df_staging[df_staging['supplier_id'].isin(new_ids)].copy()\n",
    "\n",
    "    # Assign supplier_key to new suppliers\n",
    "    if not new_suppliers.empty:\n",
    "        max_key = dim_suppliers_result['supplier_key'].max()\n",
    "        next_key = int(max_key) + 1 if pd.notna(max_key) else 1\n",
    "        new_suppliers.insert(0, 'supplier_key', range(next_key, next_key + len(new_suppliers)))\n",
    "        new_suppliers['is_active'] = True\n",
    "        dim_suppliers_result = pd.concat([dim_suppliers_result, new_suppliers], ignore_index=True)\n",
    "        print(f\"the new suppliers added: {len(new_suppliers)}\")\n",
    "\n",
    "    # Deactivate suppliers missing from staging\n",
    "    missing_ids = active_ids - staging_ids\n",
    "    if missing_ids:\n",
    "        for mid in missing_ids:\n",
    "            ids = dim_suppliers_result[\n",
    "                (dim_suppliers_result['supplier_id'] == mid) &\n",
    "                (dim_suppliers_result['is_active'] == True)\n",
    "            ].index\n",
    "            dim_suppliers_result.loc[ids, 'is_active'] = False\n",
    "            dim_suppliers_result.loc[ids, 'last_updated_at'] = datetime.now().isoformat(timespec='seconds')\n",
    "        print(f\"Suppliers deactivated (missing from staging): {len(missing_ids)}\")\n",
    "\n",
    "    # Now for every existing supplier, compare staging row to the current active row \n",
    "    intersect_ids = active_ids.intersection(staging_ids)\n",
    "\n",
    "    type2_count = 0\n",
    "    type1_count = 0\n",
    "\n",
    "    for sid in intersect_ids:\n",
    "        # Get active row\n",
    "        active_row = df_active_current[df_active_current['supplier_id'] == sid].iloc[0].to_dict()\n",
    "        # Get staging row\n",
    "        staging_row = df_staging[df_staging['supplier_id'] == sid].iloc[0].to_dict()\n",
    "\n",
    "        # ---- TYPE 2 CHECK ----\n",
    "        type2_changed = any(\n",
    "            str(active_row.get(c, '')) != str(staging_row.get(c, '')) \n",
    "            for c in TYPE2)\n",
    "\n",
    "        if type2_changed:\n",
    "            # 1 seactivate current row in dim_suppliers_result\n",
    "            ids = dim_suppliers_result[\n",
    "                (dim_suppliers_result['supplier_id'] == sid) \n",
    "                & (dim_suppliers_result['is_active'] == True)].index\n",
    "\n",
    "            dim_suppliers_result.loc[ids, 'is_active'] = False\n",
    "            dim_suppliers_result.loc[ids, 'last_updated_at'] = datetime.now().isoformat(timespec='seconds')\n",
    "\n",
    "            # 2 Append new TYPE 2 row\n",
    "            new_row = staging_row.copy()\n",
    "            max_key = dim_suppliers_result['supplier_key'].max()\n",
    "            new_row['supplier_key'] = int(max_key) + 1 if pd.notna(max_key) else 1\n",
    "            new_row['is_active'] = True\n",
    "            new_row['last_updated_at'] = datetime.now().isoformat(timespec='seconds')\n",
    "\n",
    "            dim_suppliers_result = pd.concat(\n",
    "                [dim_suppliers_result, pd.DataFrame([new_row])],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "            type2_count += 1\n",
    "\n",
    "            continue  # Skip 1 if 2 happened\n",
    "\n",
    "        # ---- TYPE 1 CHECK ----\n",
    "        type1_changed = any(str(active_row.get(c, '')) != str(staging_row.get(c, '')) for c in TYPE1)\n",
    "\n",
    "        if type1_changed:\n",
    "            ids = dim_suppliers_result[\n",
    "                (dim_suppliers_result['supplier_id'] == sid) &\n",
    "                (dim_suppliers_result['is_active'] == True)].index\n",
    "\n",
    "            for rid in ids:\n",
    "                for c in TYPE1:\n",
    "                    dim_suppliers_result.at[rid, c] = staging_row[c]\n",
    "\n",
    "                # Update last_updated_at but keep original\n",
    "                dim_suppliers_result.at[rid, 'last_updated_at'] = datetime.now().isoformat(timespec='seconds')\n",
    "            \n",
    "            type1_count += 1\n",
    "\n",
    "    # Save toCSV\n",
    "    dim_suppliers_result.to_csv(DIM_SUPPLIERS_PATH, index=False)\n",
    "    print(f\"Loaded: {CURRENT_DAY}\")\n",
    "    print(f\"Type 2 count: {type2_count}\")\n",
    "    print(f\"Type 1 counrt: {type1_count}\")\n",
    "load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdfb9ac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
