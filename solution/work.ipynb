{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e89bade8",
   "metadata": {},
   "source": [
    "## Notes\n",
    "---\n",
    "### SCD Type 2 Triggers (new row):\n",
    "- `supplier_name`\n",
    "- `supplier_category`\n",
    "- `city`\n",
    "- `delivery_frequency`\n",
    "- `email`\n",
    "\n",
    "> Create new row, assign new `supplier_key`, mark `is_active` as `True`, mark old row's `is_active` as `False`\n",
    "\n",
    "### SCD Type 1 Triggers (overwrite):\n",
    "- `notes`\n",
    "- `is_active`\n",
    "\n",
    "> Just overwrite these bro\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdef1002",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ccc74c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data/day1/supplier_details.csv and suppliers.csv into pandas\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Variable day (change this )\n",
    "CURRENT_DAY = 'day2'\n",
    "\n",
    "# Paths\n",
    "DIM_SUPPLIERS_PATH = \"dim_suppliers.csv\"\n",
    "DETAILS_PATH = f\"../data/{CURRENT_DAY}/supplier_details.csv\"\n",
    "SUPPLIERS_PATH = f\"../data/{CURRENT_DAY}/suppliers.csv\"\n",
    "\n",
    "# Triggers\n",
    "TYPE2 = [\"supplier_name\",\"supplier_category\",\"city\",\"delivery_frequency\",\"email\"]\n",
    "TYPE1 = [\"notes\",\"is_active\"]\n",
    "\n",
    "# Daily Dataframes\n",
    "details = pd.read_csv(DETAILS_PATH)\n",
    "suppliers = pd.read_csv(SUPPLIERS_PATH)\n",
    "\n",
    "# Ensure that there is a dim_suppliers to work with\n",
    "if os.path.exists(DIM_SUPPLIERS_PATH):\n",
    "    dim_suppliers = pd.read_csv(DIM_SUPPLIERS_PATH) # probably still empty\n",
    "else:\n",
    "    dim_suppliers = pd.DataFrame() # start empty\n",
    "\n",
    "\n",
    "\n",
    "# just to make the day mapping a bit more dynamic\n",
    "def get_days_mapping(day: str):\n",
    "    days_mapping = {\n",
    "        # skipping day 1 since we don't really know the actual source day\n",
    "        'day1' : '',\n",
    "        'day2' : '2025-01-01',\n",
    "        'day3' : '2025-01-02'\n",
    "    }\n",
    "    return days_mapping[day]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fc8478",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9416cac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suppliers:    SupplierID          SupplierName SupplierCategory         City  IsActive\n",
      "0         101  BeanRoasters Company     Coffee Beans      Toronto      True\n",
      "1         102    SweetTreats Bakery           Bakery  Mississauga      True\n",
      "2         103       MapleMilk Dairy     Milk & Dairy      Toronto      True\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "details:    SupplierID                     Email DeliveryFrequency  \\\n",
      "0         101  contact@beanroasters.com            Weekly   \n",
      "1         102       info@sweettreats.ca             Daily   \n",
      "2         103        sales@maplemilk.ca            Weekly   \n",
      "\n",
      "                                Notes  \n",
      "0  Name updated and expanded offering  \n",
      "1                      Same as before  \n",
      "2          Changed delivery frequency  \n",
      "||||||||||||||||||||||||||||||||||| [Data Types for Reference] |||||||||||||||||||||||||||||||||||\n",
      "SupplierID           int64\n",
      "SupplierName        object\n",
      "SupplierCategory    object\n",
      "City                object\n",
      "IsActive              bool\n",
      "dtype: object \n",
      "\n",
      "\n",
      " SupplierID            int64\n",
      "Email                object\n",
      "DeliveryFrequency    object\n",
      "Notes                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "def clean(df_supp, df_det):\n",
    "    # strip whitespace from strings\n",
    "    df_supp = df_supp.map(lambda x: x.strip() if isinstance (x, str) else x)\n",
    "    df_det = df_det.map(lambda x: x.strip() if isinstance (x, str) else x)\n",
    "    # lowercase all emails\n",
    "    df_det[\"Email\"] = df_det[\"Email\"].str.lower()\n",
    "\n",
    "    # suppliers.dtypes already shows 'is_active' as bool\n",
    "\n",
    "    return df_supp, df_det\n",
    "\n",
    "suppliers, details = clean(suppliers, details)\n",
    "print(\"suppliers:\",suppliers.head(3))\n",
    "print(\"\\n\" + \"-\"*90)\n",
    "print(\"details:\",details.head(3))\n",
    "print(f\"{\"|\"*35} [Data Types for Reference] {\"|\"*35}\")\n",
    "print(f\"{suppliers.dtypes} \\n\\n\\n {details.dtypes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced9fd10",
   "metadata": {},
   "source": [
    "# Staging & Metadata\n",
    "---\n",
    "### Notes:\n",
    "- first day has only 8 entreis anyway\n",
    "- `source_date` for day 1 will be null since we don't *actually know* the source date.\n",
    "  - day 2 will have a source date of '2025-01-01'\n",
    "  - day 3 will have a source date of '2025-01-02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "db3e02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stage(df_supp, df_det, day='day1'):\n",
    "    # merge the two dataframes based on the supplier_id\n",
    "    df_staging = df_supp.merge(df_det, on=\"SupplierID\", how=\"inner\")\n",
    "\n",
    "    # rename columns for consistency\n",
    "    df_staging = df_staging.rename(columns={\n",
    "        'SupplierID': 'supplier_id',\n",
    "        'SupplierName': 'supplier_name',\n",
    "        'SupplierCategory': 'supplier_category',\n",
    "        'City': 'city',\n",
    "        'IsActive': \"is_active\",\n",
    "        'Email': 'email',\n",
    "        'DeliveryFrequency': 'delivery_frequency',\n",
    "        'Notes': 'notes'\n",
    "    })\n",
    "\n",
    "    # Add the supplier_key column for later\n",
    "    df_staging.insert(0, 'supplier_key', range(1, len(df_staging) + 1))\n",
    "\n",
    "    # Drop the duplicate column (i kept having errors here)\n",
    "    if 'supplier_id.1' in df_staging.columns:\n",
    "        df_staging = df_staging.drop(columns=['supplier_id.1'])\n",
    "\n",
    "    # -- add metadata --\n",
    "    # add the source date\n",
    "    df_staging.insert(len(df_staging.columns), \"source_date\", get_days_mapping(day), allow_duplicates=True)\n",
    "    \n",
    "    # update \"last_updated_at\" using isoformat\n",
    "    df_staging.insert(len(df_staging.columns), \"last_updated_at\", datetime.now().isoformat(timespec='seconds'), allow_duplicates=True)\n",
    "\n",
    "    return df_staging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d5f408",
   "metadata": {},
   "source": [
    "# Load Current Dimension & Delta Detection/SCD Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a6c44eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding deltas for day: 2\n"
     ]
    }
   ],
   "source": [
    "def load():\n",
    "    # Get the staging & active df\n",
    "    df_staging = stage(suppliers, details, CURRENT_DAY)\n",
    "    df_active = dim_suppliers\n",
    "\n",
    "    # -------- Dat 1: Initial Load ------------\n",
    "    # If we're in day 1, load the entire thing since it has no deltas\n",
    "    if df_active.empty:\n",
    "        df_staging.to_csv(DIM_SUPPLIERS_PATH, index=False)\n",
    "        print(\"day 1\")\n",
    "        return\n",
    "\n",
    "    # -------- Day 2+: Loads  --------\n",
    "    print(\"Finding deltas for day:\", CURRENT_DAY[-1]) # lowkey overkill\n",
    "\n",
    "    # Get the rows that are active\n",
    "    df_active_current = df_active[df_active['is_active'] == True].copy()\n",
    "    \n",
    "    # -------- Compare 'df_active_current' with 'df_staging' --------\n",
    "    dim_suppliers_result = df_active.copy() # The df we will be updating & loading into the csv\n",
    "\n",
    "    # Reset indicies (for some reason they're different)\n",
    "    df_active_current = df_active_current.reset_index(drop=True)\n",
    "    df_staging = df_staging.reset_index(drop=True)\n",
    "\n",
    "    # [Get New Suppliers and append to the result]\n",
    "    active_ids = set(df_active_current['supplier_id'])\n",
    "    staging_ids = set(df_staging['supplier_id'])\n",
    "    new_ids = staging_ids-active_ids\n",
    "    new_suppliers = df_staging[df_staging['supplier_id'].isin(new_ids)]\n",
    "\n",
    "    # Append new \n",
    "    dim_suppliers_result = pd.concat([dim_suppliers_result, new_suppliers])\n",
    "\n",
    "    # Now for every existing supplier, compare staging row to the current active row \n",
    "\n",
    "\n",
    "load()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
